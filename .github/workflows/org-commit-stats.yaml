name: Org Commit Insights (1500d commits + weekly LOC, summary-only)

on:
  workflow_dispatch:
    inputs:
      compute_loc:
        description: "Compute LOC (true/false). Default false for manual runs."
        required: false
        default: "true"
  schedule:
    - cron: "0 6 * * 1" # every Monday 06:00 UTC

env:
  ORG_NAME: Ludo-MVP

permissions:
  contents: write

concurrency:
  group: org-commit-insights
  cancel-in-progress: true

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Verify gh is available
        run: gh --version

      - name: Generate GitHub App token
        id: app-token
        uses: actions/create-github-app-token@v1
        with:
          app-id: ${{ secrets.GH_APP_ID }}
          private-key: ${{ secrets.GH_APP_PRIVATE_KEY }}
          owner: ${{ env.ORG_NAME }}

      - name: Install cloc (only when LOC is enabled)
        if: ${{ github.event_name == 'schedule' || inputs.compute_loc == 'true' }}
        shell: bash
        run: |
          set -euo pipefail
          sudo apt-get update -y
          sudo apt-get install -y cloc

      - name: Generate Markdown report (summary-only)
        env:
          GH_TOKEN: ${{ steps.app-token.outputs.token }}
        shell: bash
        run: |
          set -euo pipefail

          ORG_LOGIN="${ORG_NAME}"          # for API
          ORG_LABEL="Ludo Labs AG"         # for report display (always fixed)
          OUT="commits.md"
          SINCE="$(date -u -d '1500 days ago' +%Y-%m-%d)"

          # LOC computed on schedule by default; manual runs can enable via input.
          COMPUTE_LOC="false"
          if [[ "${GITHUB_EVENT_NAME}" == "schedule" ]]; then
            COMPUTE_LOC="true"
          else
            COMPUTE_LOC="${{ inputs.compute_loc || 'false' }}"
          fi

          SELF_REPO="${GITHUB_REPOSITORY}"

          # Fetch repos and apply filters:
          # - exclude forks and archived
          # - exclude the current repo running the workflow
          # - exclude any repo whose name contains "backup" (case-insensitive)
          mapfile -t REPOS < <(
            gh api "orgs/${ORG_LOGIN}/repos?per_page=100" --paginate \
              --jq '.[] | select(.fork==false and .archived==false) | .full_name' \
            | grep -v -F "${SELF_REPO}" \
            | grep -vi 'backup' || true
          )

          total_commits=0
          processed=0
          skipped=0
          active_repos=0

          total_loc=0
          loc_counted=0
          loc_skipped=0

          get_repo_commit_count() {
            local repo="$1"
            local since="$2"
            local tries=0
            local max_tries=6

            while (( tries < max_tries )); do
              tries=$((tries+1))

              local resp status body
              resp="$(gh api -i -H "Accept: application/vnd.github.cloak-preview+json" \
                "/search/commits?q=repo:${repo}+committer-date:>=${since}&per_page=1" 2>/dev/null || true)"

              status="$(printf "%s" "$resp" | head -n 1 | awk '{print $2}')"
              body="$(printf "%s" "$resp" | awk 'BEGIN{p=0} /^\r?$/{p=1;next} {if(p)print}')"

              if [[ "$status" == "200" ]]; then
                echo "$body" | jq -r '.total_count // 0' 2>/dev/null || echo 0
                return 0
              fi

              if [[ "$status" == "403" ]]; then
                sleep $((10 * tries))
                continue
              fi

              echo ""
              return 1
            done

            echo ""
            return 1
          }

          get_repo_loc() {
            local repo="$1"
            local dir="__repo_tmp_${RANDOM}_${RANDOM}"

            git clone --quiet --depth 1 "https://x-access-token:${GH_TOKEN}@github.com/${repo}.git" "${dir}" || return 1

            local loc
            loc="$(cloc "${dir}" --json --quiet 2>/dev/null | jq -r '.SUM.code // 0' || echo 0)"

            rm -rf "${dir}"
            echo "${loc}"
          }

          # Throttle to respect Search API rate limits (~30 req/min)
          # 2.2s => ~27 req/min
          for repo in "${REPOS[@]}"; do
            sleep 2.2

            c="$(get_repo_commit_count "${repo}" "${SINCE}" || true)"
            if [[ -z "${c}" ]] || ! [[ "${c}" =~ ^[0-9]+$ ]]; then
              skipped=$((skipped+1))
              continue
            fi

            processed=$((processed+1))
            total_commits=$((total_commits + c))

            if (( c > 0 )); then
              active_repos=$((active_repos+1))

              if [[ "${COMPUTE_LOC}" == "true" ]]; then
                loc="$(get_repo_loc "${repo}" || true)"
                if [[ -z "${loc}" ]] || ! [[ "${loc}" =~ ^[0-9]+$ ]]; then
                  loc_skipped=$((loc_skipped+1))
                else
                  loc_counted=$((loc_counted+1))
                  total_loc=$((total_loc + loc))
                fi
              fi
            fi
          done

          {
            echo "# Organization Commit Insights"
            echo
            echo "**Org:** ${ORG_LABEL}  "
            echo "**Commits period:** last 1500 days (since ${SINCE}, all branches)  "
            echo "**LOC:** $([[ "${COMPUTE_LOC}" == "true" ]] && echo "computed weekly for repos with commits > 0" || echo "not computed")  "
            echo "**Generated:** $(date -u +"%Y-%m-%d %H:%M UTC")"
            echo
            echo "## Summary"
            echo "- **Total commits (1500d):** ${total_commits}"
            echo "- **Repositories counted (commits):** ${processed}"
            echo "- **Repositories skipped (commits):** ${skipped}"
            echo "- **Active repos (commits > 0):** ${active_repos}"
            echo "- **Total LOC (active repos only):** ${total_loc}"
            echo "- **Repositories counted (LOC):** ${loc_counted}"
            echo "- **Repositories skipped (LOC):** ${loc_skipped}"
          } > "${OUT}"

          echo "Report written to ${OUT}"
          cat "${OUT}"

      - name: Generate charts (PNG) and embed into Markdown
        env:
          GH_TOKEN: ${{ steps.app-token.outputs.token }}
          ORG_LOGIN: ${{ env.ORG_NAME }}
        shell: bash
        run: |
          set -euo pipefail

          SINCE="$(date -u -d '30 days ago' +%Y-%m-%d)"
          UNTIL="$(date -u +%Y-%m-%d)"
          OUT_MD="commits.md"
          OUT_PNG="commits_30d.png"

          # Build day list (UTC)
          python - <<'PY'
          import os, subprocess, json
          from datetime import datetime, timedelta, timezone

          org = os.environ["ORG_LOGIN"]
          since = os.environ.get("SINCE")
          until = os.environ.get("UNTIL")

          def sh(cmd):
            return subprocess.check_output(cmd, text=True)

          since_dt = datetime.strptime(since, "%Y-%m-%d").replace(tzinfo=timezone.utc)
          until_dt = datetime.strptime(until, "%Y-%m-%d").replace(tzinfo=timezone.utc)

          # We will count commits per day via Search API.
          # To reduce payload, per_page=1 and take total_count.
          # Note: Search API rate limits are low. 30 daily queries is OK weekly.
          days = []
          cur = since_dt
          while cur <= until_dt:
            nxt = cur + timedelta(days=1)
            q = f"/search/commits?q=org:{org}+committer-date:>={cur.date()}+committer-date:<{nxt.date()}&per_page=1"
            # gh api with required Accept header for commit search
            resp = sh(["gh","api","-H","Accept: application/vnd.github.cloak-preview+json", q])
            total = json.loads(resp).get("total_count", 0)
            days.append((cur.date().isoformat(), int(total)))
            cur = nxt

          # Save as json for plotting
          with open("commits_30d.json","w",encoding="utf-8") as f:
            json.dump(days, f)
          PY

          # Plot with matplotlib
          python - <<'PY'
          import json
          import matplotlib.pyplot as plt

          data = json.load(open("commits_30d.json","r",encoding="utf-8"))
          labels = [d[0] for d in data]
          values = [d[1] for d in data]

          plt.figure(figsize=(12,4))
          plt.plot(range(len(values)), values)
          plt.xticks(range(0,len(labels), max(1, len(labels)//10)), [labels[i] for i in range(0,len(labels), max(1, len(labels)//10))], rotation=45, ha="right")
          plt.ylabel("Commits")
          plt.title("Org commits per day (last 30 days)")
          plt.tight_layout()
          plt.savefig("commits_30d.png", dpi=150)
          PY

          # Insert chart near the top (after the header block)
          # If already embedded, replace the image line.
          if grep -qE '^!\[Org commits per day' "${OUT_MD}"; then
            perl -i -pe 's/^!\[Org commits per day.*$/![Org commits per day (last 30 days)](commits_30d.png)/' "${OUT_MD}"
          else
            # Insert after the first blank line following the title
            perl -0777 -i -pe 's/(# Organization Commit Insights\n\n)/$1![Org commits per day (last 30 days)](commits_30d.png)\n\n/' "${OUT_MD}"
          fi

          echo "Chart written to commits_30d.png and embedded into commits.md"

      - name: Commit & push report
        shell: bash
        run: |
          set -euo pipefail
          git config user.name "github-actions"
          git config user.email "actions@github.com"

          git add commits.md

          if git diff --cached --quiet; then
            echo "No changes to commit."
            exit 0
          fi

          git commit -m "Update org commit insights (1500d + weekly LOC, summary-only)"
          git push
